# Проект: Классификация видов спорта с использованием сверточных нейронных сетей 

Для обучения и тестирования использован датасет с Kaggle:  
[Sports Image Classification Dataset](https://www.kaggle.com/datasets/gpiosenka/sports-classification).

Мы поставили цель:  
**Сравнить две архитектуры нейронных сетей** и определить, какая лучше подходит для этой задачи:
- **SimpleCNN** — простая сверточная нейронная сеть.
- **CNNWithResidual** — сверточная сеть с остаточными (residual) блоками.

Состав проекта:
- `dataset.py` — подготовка датасета, аугментации.
- `models.py` — определение моделей (SimpleCNN, CNNWithResidual).
- `trainer.py` — функции обучения моделей.
- `utils.py` — вспомогательные утилиты (построение графиков, подсчет параметров).
- `experiments_simple_cnn.ipynb` — эксперименты с SimpleCNN.
- `experiments_cnn_with_res.ipynb` — эксперименты с CNNWithResidual.
- `final_model_run.ipynb` — запуск финальной выбранной модели.

Начнем с простой сверточной сети. (Все эксперименты с ней просиходили в файле - experiments_simple_cnn)

В архитектуре `SimpleCNN` для активации используется функция **ReLU (Rectified Linear Unit)** после каждого сверточного слоя.  
Для стабилизации обучения после сверточных слоев применяется **Batch Normalization**, что помогает ускорить сходимость.  
Для борьбы с переобучением в сети используется **Dropout**. 

В первую очередь мы подобрали оптимальную глубину для простой сверточной сети. Были рассмотрены три варианта: глубина 2, 4 и 6 сверточных слоев. Все модели обучались на одном и том же датасете в течение 5 эпох для корректного сравнения.\
Глубина 2.\
<img width="1200" height="400" alt="image" src="https://github.com/user-attachments/assets/550fec79-4181-47bb-adc9-8f95058f311c" />\
Глубина 4.\
<img width="1202" height="403" alt="image" src="https://github.com/user-attachments/assets/8e7eefa7-9259-4949-9aea-097cbd0f4517" />\
Глубина 6.\
<img width="1198" height="399" alt="image" src="https://github.com/user-attachments/assets/d33143e7-54c3-47aa-bef4-c4aca433213e" />\
По графикам видно, что при увеличении глубины до 6 слоев модель показывала стабильный рост точности на тестовой выборке и меньший тестовый лосс, в то время как при меньшей глубине результаты были хуже.\
Вывод: глубина 6 была выбрана как оптимальная, так как обеспечивала наилучший баланс между качеством предсказаний и устойчивостью обучения.

На глубине 6 слоев мы проверили эффективность работы модели при различных размерах ядра свёртки: 3, 5 и 7.\
Время обучения для каждого случая составило:ядро 3: 109.13 сек, ядро 5: 140.82 сек, ядро 7: 604.57 сек.\
Ядро 3x3\
<img width="1194" height="399" alt="image" src="https://github.com/user-attachments/assets/678466b8-911b-49f8-b577-42111c4e2113" />\
Ядро 5x5\
<img width="1198" height="398" alt="image" src="https://github.com/user-attachments/assets/0bfe7350-fb51-48b4-a1ae-bb95889c175a" />\
Ядро 7x7\
<img width="1202" height="399" alt="image" src="https://github.com/user-attachments/assets/9866f1cd-4f3f-4b02-8c94-96ffa31691cf" />\
Лучшие метрики по точности  показали варианты с ядрами 5 и 7, однако из-за существенного увеличения времени обучения при ядре 7 оптимальным решением оказалось использование ядра 5.

Далее модель была запущена на 50 эпохах с глубиной 6 и ядром 5 для оценки её устойчивости. Время обучения - 1705секунд.\
<img width="1192" height="394" alt="image" src="https://github.com/user-attachments/assets/abdff410-a072-4c04-bb50-d10f11a9aabe" />\
По результатам видно, что модель демонстрирует признаки переобучения: training loss продолжает снижаться почти до нуля, а training accuracy достигает 100%, тогда как test loss остаётся колеблющимся,\
а testaccuracy стабилизируется на уровне около 75%. Это говорит о том, что модель слишком хорошо запомнила обучающую выборку и недостаточно обобщает на валидационных данных.

Добавили аугментацию для улучшения её способности к обобщению.\
Применённые аугментации включают:\
RandomResizedCrop — случайная обрезка с изменением масштаба\
RandomHorizontalFlip — случайное горизонтальное отражение\
ColorJitter — изменение яркости, контраста и насыщенности\
RandomRotation — случайный поворот до 15 градусов\
<img width="1184" height="387" alt="image" src="https://github.com/user-attachments/assets/59993963-c320-46ed-9ca6-07c2a3dc7b0e" />\
Результат оказался вполне удовлетворительным: модель демонстрирует стабильное снижение test loss примерно до 1.0 и рост test accuracy до около 70%. Время обучения составило 3155 секунд.



Теперь рассмотрим сверточную нейронную сеть с остаточными блоками.\
Для оценки эффективности были протестированы три варианта глубины при обучении на протяжении 5 эпох:\
Глубина 1 — 1 residual-блок (всего 2 сверточных слоя), время обучения: 214.70 секунд.\
<img width="1199" height="397" alt="image" src="https://github.com/user-attachments/assets/9d140f82-961f-46f8-867b-0f9565b8ded9" />\
Глубина 3 — 3 residual-блока (всего 7 сверточных слоев), время обучения: 285.02 секунд.\
<img width="1197" height="400" alt="image" src="https://github.com/user-attachments/assets/664e6583-0212-4373-8a1a-11101506e3f8" />\
Глубина 5 — 5 residual-блоков (всего 11 сверточных слоев), время обучения: 335.45 секунд.\
<img width="1195" height="399" alt="image" src="https://github.com/user-attachments/assets/96623605-af83-4b76-b43a-0d84c30163d1" />\
По результатам графиков видно, что при увеличении глубины сеть демонстрирует снижение потерь и рост точности на тестовой выборке. Лучший выбор пал на глубину 5 (11 сверточных слоев).

Теперь для этой глубины подберем ядро. Также 5 эпох.\
3x3. Время обучения - 331 секунда.\
<img width="1197" height="399" alt="image" src="https://github.com/user-attachments/assets/18517861-d819-4629-876d-8063ab72dc0b" />\
5x5. Время обучения - 435 секунд.\
<img width="1197" height="396" alt="image" src="https://github.com/user-attachments/assets/bebf994e-2514-4485-afa5-c12a679adbea" />\
7x7. Время обучения - 601 секунд.\
<img width="1200" height="398" alt="image" src="https://github.com/user-attachments/assets/ca6318e6-bb1f-432c-960f-f08dcdd36a62" />\
Лучший вариант относительно времени и точности - 3x3.

Далее модель была запущена на 30 эпохах с глубиной 11 и ядром 3 на протяжении 30 эпох. Время - 2040 секунд.\
<img width="1199" height="398" alt="image" src="https://github.com/user-attachments/assets/590738e7-59a6-481a-95f6-efc11477c2bc" />\
Вывод: полученная точность достаточно неплохая (около 73%) и модель показывает стабильное обучение, однако для дальнейшего улучшения стоит попробовать запуск с аугментацией данных, чтобы повысить обобщающую\ способность модели. Аугментации те же, что и у простой сверточной модели.\

<img width="1189" height="390" alt="image" src="https://github.com/user-attachments/assets/c3a4ac62-f1df-46c0-a9ee-16926c91a8aa" />\
Обучили модель на 60 эпохах, получили стабильный результат: test loss снижается примерно до 0.65, а test accuracy достигает около 80%. Результат можно считать хорошим — модель\
уверенно обобщает данные без признаков переобучения. Как лучшую модель мы выбираем ее.
















